<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2025-07-29T10:04:56-04:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Robot psychologistâ€™s blog</title><subtitle>Welcome to Robot Psychologist&apos;s Blog â€” a blog where I unpack the inner workings of intelligent systems, one curious question at a time.  I&apos;m a PhD student in AI with a BSc in neuroscience and psychology, and this is my space to explore the ideas. If you&apos;re into how intelligent systems (human or artificial) learn, adapt, and act, you&apos;ll feel right at home.
</subtitle><author><name>Busra Tugce Gurbuz</name><email></email></author><entry><title type="html">From BYOL to JEPA: How Studentâ€“Teacher Networks Quietly Became the Brains Behind World Models</title><link href="http://localhost:4000/ssl/2024/07/29/ts_world_models.html" rel="alternate" type="text/html" title="From BYOL to JEPA: How Studentâ€“Teacher Networks Quietly Became the Brains Behind World Models" /><published>2024-07-29T00:00:00-04:00</published><updated>2024-07-29T00:00:00-04:00</updated><id>http://localhost:4000/ssl/2024/07/29/ts_world_models</id><content type="html" xml:base="http://localhost:4000/ssl/2024/07/29/ts_world_models.html"><![CDATA[<p>Training an agent that can reason about its environmentâ€”without groundâ€‘truth labelsâ€”requires a robust internal simulator, often called a <strong>world model</strong>.  Among the many ideas in selfâ€‘supervised learning (SSL), the <strong>studentâ€“teacher paradigm</strong> has proven repeatedly effective at producing the highâ€‘quality representations that such world models depend on.</p>

<p>This post explains how studentâ€“teacher SSL works, why it has been influential and might be important for building better world models.</p>

<h3 id="what-is-a-studentteacher-network">What Is a Studentâ€“Teacher Network?</h3>

<p>A studentâ€“teacher setup contains two networks:</p>

<ul>
  <li><strong>Teacher</strong> â€“ Provides target features or predictions.</li>
  <li><strong>Student</strong> â€“ Trains to match those targets across augmented views of the same input.</li>
</ul>

<p>The teacher is usually an <strong>exponential moving average (EMA)</strong> of the student, so its parameters evolve slowly and provide a stable learning signal.  Because targets come from the model itself rather than external labels, the approach scales to unlabeled data.</p>

<h3 id="why-it-works">Why It Works</h3>

<ul>
  <li><strong>Soft targets carry richer information</strong> than oneâ€‘hot labels, exposing interâ€‘class structure and uncertainty.</li>
  <li><strong>Temporal smoothing</strong> via EMA aggregates knowledge over many updates, acting like an implicit ensemble.</li>
  <li><strong>Augmentation consistency</strong> forces invariance to viewpoint, color, cropping and other realâ€‘world nuisance factors.</li>
</ul>

<h3 id="a-brief-historical-detour">A Brief Historical Detour</h3>

<p>The studentâ€“teacher idea is far from new; it has surfaced in diverse corners of SSL for nearly a decade.</p>

<ul>
  <li><strong>Temporal Ensembling (2017)</strong> â€“ Improved semiâ€‘supervised classification by averaging model predictions over multiple epochs.</li>
  <li><strong>Mean Teacher (2017)</strong> â€“ Used EMA weights explicitly to create a teacher for consistency regularisation.</li>
  <li><strong>MoCo (2019)</strong> â€“ Employed a momentum encoder (teacher) to populate a memory bank for contrastive learning.</li>
  <li><strong>BYOL (2020)</strong> â€“ Demonstrated that a student can learn useful features from an EMA teacher without any negative pairs.</li>
  <li><strong>DINO (2021)</strong> â€“ Showed that applying centering and sharpening to teacher outputs prevents collapse at scale.</li>
  <li><strong>JEPA family (2023â€¯â€“â€¯present)</strong> â€“ Recasts the studentâ€“teacher idea as <strong>maskedâ€‘region prediction</strong>: the student, given only a partial view, predicts the teacherâ€™s features for the hidden region.  This simple shift from view alignment to spatial prediction yields objectâ€‘centric, forwardâ€‘looking representationsâ€”ideal for worldâ€‘model objectives.</li>
  <li><strong>Speech, NLP and Multimodal Work</strong> â€“ Similar momentumâ€‘distillation ideas power HuBERT, CLIP variants, and more.</li>
</ul>

<h4 id="why-this-lineage-matters">Why This Lineage Matters</h4>

<ol>
  <li><strong>Evidence of robustness</strong> â€“ The same principle succeeds across vision, speech and language, suggesting a fundamental mechanism.</li>
  <li><strong>Design inspiration</strong> â€“ Historical tricks (memory banks, centering, sharpening, predictor asymmetry) offer a toolbox for future models.</li>
  <li><strong>Theoretical grounding</strong> â€“ Understanding how targets evolve sheds light on why collapse happens and how to avoid it.</li>
  <li><strong>Transferable intuition</strong> â€“ Insights gained in vision often translate to other modalities, accelerating crossâ€‘domain progress.</li>
</ol>

<h3 id="moving-beyond-contrastive-learning">Moving Beyond Contrastive Learning</h3>

<p>Early SSL methods such as SimCLR and InfoNCE relied on negative pairs: anchorâ€‘positive similarities were maximised while anchorâ€‘negative similarities were minimised.  This led to:</p>

<ul>
  <li>Large batchâ€‘size requirements.</li>
  <li>Risk of <strong>false negatives</strong> when semantically similar images were pushed apart.</li>
  <li>Additional engineering (memory banks, distributed synchronisation).</li>
</ul>

<p>Studentâ€“teacher methods sidestep these issues by <strong>removing negatives altogether</strong>.  Instead, learning is driven by matching the teacherâ€™s targets, greatly simplifying training and improving stability.</p>

<h3 id="collapse-and-how-to-avoid-it">Collapse and How to Avoid It</h3>

<p>Removing negatives introduces a new risk: the student may converge to a trivial solution where every input maps to the same embedding, a phenomenon known as â€œcollapseâ€.</p>

<ul>
  <li><strong>BYOL</strong> counters this with architectural asymmetry (student has an extra predictor) and EMA updates.</li>
  <li><strong>DINO</strong> keeps both networks identical but applies two regularisers:
    <ul>
      <li><strong>Centering</strong> subtracts a running mean to prevent feature domination.</li>
      <li><strong>Sharpening</strong> uses lowâ€‘temperature softmax to encourage confident, nonâ€‘uniform outputs.</li>
    </ul>
  </li>
</ul>

<p>These tricks maintain diversity without reâ€‘introducing negatives.</p>

<h3 id="why-studentteacher-ssl-is-good-for-world-models">Why Studentâ€“Teacher SSL Is Good for World Models</h3>

<p>World models could require learning from vast streams of partially observed, noisy dataâ€”exactly where labels are hardest to obtain.  Studentâ€“teacher SSL provides:</p>

<ul>
  <li><strong>Labelâ€‘free scalability</strong> â€“ Works on billions of internet images, raw video, agent rollouts or multimodal corpora.</li>
  <li><strong>Stability</strong> â€“ EMA teachers and regularisation avoid collapse and noisy gradients.</li>
  <li><strong>Computational efficiency</strong> â€“ No need for giant batches or external memory structures.</li>
  <li><strong>Modality agnosticism</strong> â€“ Proven in vision, speech and language, making it ideal for unified, multiâ€‘sensor world models.</li>
</ul>

<p>Consider JEPA as a concrete variation: rather than aligning two augmented views of the same input, it trains the student to predict the teacherâ€™s representation of a masked region using only partial context. This predictive setup still relies on a studentâ€“teacher framework (with an EMA teacher), but shifts the objective toward inferring latent structure.  Variants of this idea could lead to increasingly powerful and scalable pretraining strategies for world models.</p>

<h3 id="key-takeaways">Key Takeaways</h3>

<ol>
  <li>
    <p><strong>Proven across tasks and modalities</strong><br />
Studentâ€“teacher SSL has driven breakthroughs from Mean Teacher and MoCo to BYOL, DINO, and the JEPA family, as well as in speech (HuBERT) and multimodal settings (CLIP variants). Its repeated success points to a broadly applicable learning principle.</p>
  </li>
  <li>
    <p><strong>Evolving design space</strong><br />
Classic tricksâ€”memory banks, centering, sharpening, predictor asymmetryâ€”remain useful, while newer predictive variants such as JEPA demonstrate that simply changing <em>what</em> the student predicts (alignment vs. maskedâ€‘region inference) can open entirely new capabilities.</p>
  </li>
  <li>
    <p><strong>Simpler and more computeâ€‘friendly than contrastive methods</strong><br />
By eliminating negative pairs and large batch requirements, studentâ€“teacher approaches reduce engineering overhead and make largeâ€‘scale pretraining more accessible.</p>
  </li>
  <li>
    <p><strong>Well matched to worldâ€‘model objectives</strong><br />
The consistencyâ€‘based signals that guide studentâ€“teacher SSL align naturally with the need to infer hidden or future state. JEPAâ€™s maskedâ€‘region prediction shows how the same machinery can be adapted for forwardâ€‘simulation tasks.</p>
  </li>
  <li>
    <p><strong>Valuable, but not the only tool</strong><br />
A strong grasp of studentâ€“teacher SSL provides a practical head start for building richer world models, yet it can be complemented with other techniquesâ€”contrastive objectives, generative modeling, or reinforcement learningâ€”to meet specific domain requirements.</p>
  </li>
</ol>]]></content><author><name>Busra Tugce Gurbuz</name></author><category term="ssl" /><summary type="html"><![CDATA[Training an agent that can reason about its environmentâ€”without groundâ€‘truth labelsâ€”requires a robust internal simulator, often called a world model. Among the many ideas in selfâ€‘supervised learning (SSL), the studentâ€“teacher paradigm has proven repeatedly effective at producing the highâ€‘quality representations that such world models depend on.]]></summary></entry><entry><title type="html">Stop Letting Your GPU Nap: Stack Jobs and Supercharge Your Experiments</title><link href="http://localhost:4000/compute/2024/07/22/use_your_GPUs.html" rel="alternate" type="text/html" title="Stop Letting Your GPU Nap: Stack Jobs and Supercharge Your Experiments" /><published>2024-07-22T00:00:00-04:00</published><updated>2024-07-22T00:00:00-04:00</updated><id>http://localhost:4000/compute/2024/07/22/use_your_GPUs</id><content type="html" xml:base="http://localhost:4000/compute/2024/07/22/use_your_GPUs.html"><![CDATA[<p><em>Tips for ML researchers on shared clusters who are tired of slow experiments and sleepy GPUs.</em></p>

<hr />

<h3 id="wait-why-is-my-gpu-so-bored-">Wait, Why Is My GPU So Bored? ğŸ¥¹</h3>

<p>Ever peeked at <code class="language-plaintext highlighter-rouge">nvidia-smi</code> mid-training and felt personally offended by a <strong>15% GPU utilization</strong> reading?</p>

<p>Youâ€™re not alone.</p>

<p>In many ML setupsâ€”especially in deep reinforcement learning or self-supervised learningâ€”the GPU ends up spending more time <strong>waiting around</strong> than doing actual work. Hereâ€™s why:</p>

<ul>
  <li>Your model might be <strong>tiny</strong> (looking at you, MLPs and small CNNs).</li>
  <li><strong>Environment steps</strong> in RL live on the CPU and take their sweet time.</li>
  <li><strong>Data augmentation</strong> and preprocessing often clog the CPU while the GPU twiddles its thumbs.</li>
  <li>Even classic vision or SimCLR jobs on CIFAR-10 barely dent the surface of a modern A100â€™s power.</li>
</ul>

<p>Moral of the story? <strong>Youâ€™ve got untapped compute just sitting there.</strong></p>

<h3 id="signs-of-gpu-underuse">Signs of GPU Underuse</h3>

<p>Hereâ€™s how to know your GPUâ€™s taking a nap:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">nvidia-smi</code> shows <strong>plenty of free VRAM</strong> (e.g., using 5 GB out of 40 GB).</li>
  <li>Compute â€œUtilâ€ column idles in the teens while the CPU sits near 100 %.
    <ul>
      <li>Example: a fastai ResNet-18 computer-vision run on an A100 sat at ~20 % util with memory to spare (<a href="https://stackoverflow.com/questions/75553862/low-utilization-of-the-a100-gpu-with-fastai">reference</a>) or an RLlib DQN job with 256 k batch size still spiked only briefly above 25 %</li>
    </ul>
  </li>
</ul>

<p>You might be tempted to buy more GPUs. Donâ€™t. <strong>Use what you already have better.</strong></p>

<h3 id="the-secret-run-multiple-jobs-at-once">The Secret: Run Multiple Jobs at Once</h3>

<p>If your current job is only using a slice of the GPU, just stack more on top!</p>

<p>Hereâ€™s the magic formula:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Run three jobs in parallel</span>
<span class="k">for </span>cfg <span class="k">in </span>cfg1.yaml cfg2.yaml cfg3.yaml<span class="p">;</span> <span class="k">do
    </span>python train.py <span class="nt">--config</span> <span class="nv">$cfg</span> &amp; 
<span class="k">done
</span><span class="nb">wait</span> <span class="c"># Let them all finish before exiting</span>
</code></pre></div></div>

<p>Why it works:</p>

<ul>
  <li>
    <p>Each job uses a slice of VRAM; their peaks rarely coincide.</p>
  </li>
  <li>Streaming Multiprocessor stay busier because when one job waits on the CPU, another is mid-backprop.
    <ul>
      <li><strong>More info on SMs:</strong> Each SM handles the actual math operations (like matrix multiplies and convolutions). A100 has 108 SMs, which means it can handle a lot of parallel math â€” if you feed it well.</li>
    </ul>
  </li>
  <li>You triple sweep throughput without touching the cluster queue.</li>
</ul>

<p>This trick works great for:</p>

<ul>
  <li>Hyperparameter sweeps</li>
  <li>Seed averaging</li>
  <li>Trying three ideas because youâ€™re impatient (relatable)</li>
</ul>

<h3 id="tips-pitfalls-and-gotchas-with-explanations">Tips, Pitfalls, and Gotchas (With Explanations!)</h3>

<table>
  <thead>
    <tr>
      <th>âœ… / âš ï¸</th>
      <th>What You Should Know</th>
      <th>Why It Matters</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>âœ…</td>
      <td><strong>Leave ~10% VRAM unused</strong></td>
      <td>PyTorch loves to surprise you with memory spikes. A small buffer helps you avoid sudden OOM crashes that wipe out <em>all</em> jobs.</td>
    </tr>
    <tr>
      <td>âœ…</td>
      <td><strong>Use <code class="language-plaintext highlighter-rouge">/scratch</code> or SSD storage</strong></td>
      <td>If three jobs all hit the disk at once on slow storage, your fancy parallelism will turn into a data-loading traffic jam.</td>
    </tr>
    <tr>
      <td>âœ…</td>
      <td><strong>Tag runs in your logger (e.g., <code class="language-plaintext highlighter-rouge">wandb --group stacked</code>)</strong></td>
      <td>Keeps your dashboards from looking like a spaghetti bowl of metrics. Easier to compare, track, and brag about.</td>
    </tr>
    <tr>
      <td>âœ…</td>
      <td><strong>Watch <code class="language-plaintext highlighter-rouge">num_workers</code> and threads</strong></td>
      <td>Each job spawns data loaders. Multiply that by three and suddenly your system has 48 zombie processes hoarding RAM. Keep things lean.</td>
    </tr>
    <tr>
      <td>âš ï¸</td>
      <td><strong>Donâ€™t stack giant models</strong></td>
      <td>If youâ€™re running LLMs, ViTs, or anything eating 80%+ VRAM, justâ€¦ donâ€™t. Youâ€™ll get out-of-memory errors faster than you can say â€œSIGKILLâ€.</td>
    </tr>
    <tr>
      <td>âš ï¸</td>
      <td><strong>Know your clusterâ€™s rules</strong></td>
      <td>Some clusters have strict policies: one job per GPU, no background processes, etc. Break them, and you might lose access. Nobody wants that email.</td>
    </tr>
  </tbody>
</table>

<h3 id="tldr-">TL;DR ğŸ’›</h3>

<p><strong>If your GPU looks bored, it probably is.</strong></p>

<p>Instead of leaving it idle, stack 2â€“3 light-to-medium jobs on the same card. Youâ€™ll:</p>

<ul>
  <li>Finish sweeps 2â€“3x faster</li>
  <li>Reduce total GPU-hours</li>
  <li>Help your labmates get off the waitlist</li>
</ul>

<h3 id="your-move-">Your Move ğŸ’…</h3>

<ol>
  <li>Fire up few extra jobs.</li>
  <li>Monitor <code class="language-plaintext highlighter-rouge">nvidia-smi</code>.</li>
  <li>Watch your GPU actually break a sweat.</li>
  <li>Flex your productivity gains.</li>
</ol>

<p>You donâ€™t need more computeâ€”you just need to <strong>use it smarter</strong>.</p>]]></content><author><name>Busra Tugce Gurbuz</name></author><category term="compute" /><summary type="html"><![CDATA[Tips for ML researchers on shared clusters who are tired of slow experiments and sleepy GPUs.]]></summary></entry></feed>